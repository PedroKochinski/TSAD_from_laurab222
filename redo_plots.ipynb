{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauraboggia/VSCode_projects/TranAD/.conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'convert_to_windows' from 'main' (/Users/lauraboggia/VSCode_projects/TranAD/main.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_windows\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'convert_to_windows' from 'main' (/Users/lauraboggia/VSCode_projects/TranAD/main.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import mplhep as hep\n",
    "from src.models import TranAD, iTransformer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from data_loader import convert_to_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['axes.prop_cycle'] = cycler('color', ['#17becf','#8c564b', '#e377c2', '#7f7f7f','#bcbd22', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])\n",
    "# plt.style.use([hep.style.ROOT, hep.style.firamath])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iTransf_n_windows = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 500, 1000, 2000]\n",
    "TranAD_n_windows = [10, 20, 30, 40, 50, 60, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25\n",
    "dataset = 'SMAP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_dataset(dataset):\n",
    "# \tloader = []\n",
    "# \tfor file in ['train', 'test', 'labels']:\n",
    "# \t\tif dataset == 'SMD': file = 'machine-1-1_' + file\n",
    "# \t\tif dataset == 'SMAP': file = 'P-1_' + file\n",
    "# \t\tif dataset == 'MSL': file = 'C-1_' + file\n",
    "# \t\tif dataset == 'UCR': file = '136_' + file\n",
    "# \t\tif dataset == 'NAB': file = 'ec2_request_latency_system_failure_' + file\n",
    "# \t\tloader.append(np.load(os.path.join(f'processed/{dataset}', f'{file}.npy')))\n",
    "\t\n",
    "# \ttrain_loader = DataLoader(loader[0], batch_size=loader[0].shape[0])\n",
    "# \ttest_loader = DataLoader(loader[1], batch_size=loader[1].shape[0])\n",
    "# \tlabels = loader[2]\n",
    "# \tprint('training set shape:', train_loader.dataset.shape)\n",
    "# \tprint('test set shape:', test_loader.dataset.shape)\n",
    "# \treturn train_loader, test_loader, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plotting import plot_ascore, plot_labels, plot_metrics, compare_labels\n",
    "from main import backprop\n",
    "from src.pot import pot_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replotting(model_name, n_windows, dataset='SMAP', N=25):\n",
    "    for i, elem in enumerate(n_windows):\n",
    "        # path = f'studies/{model_name}_{dataset}_2/n_window{elem}/results'\n",
    "        model_path = f'studies/{model_name}_{dataset}_2/n_window{elem}/checkpoints/model.ckpt'\n",
    "        plot_path = f'studies/{model_name}_{dataset}_2/n_window{elem}/plots'\n",
    "\n",
    "        # initialise model etc\n",
    "        checkpoint = torch.load(model_path)\n",
    "        if model_name == 'TranAD':\n",
    "            model = TranAD(N, elem).double()\n",
    "        elif model_name == 'iTransformer':\n",
    "            model = iTransformer(N, elem).double()\n",
    "        else:\n",
    "            print('pbm with model loading')\n",
    "            break\n",
    "        optimizer = torch.optim.AdamW(model.parameters() , lr=model.lr, weight_decay=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 5, 0.9)\n",
    "        # load model etc\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        # epoch = checkpoint['epoch']\n",
    "        # accuracy_list = checkpoint['accuracy_list']\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f'total params: {total_params}, trainable params: {trainable_params}')\n",
    "\n",
    "        train_loader, test_loader, labels = load_dataset(dataset)\n",
    "        trainD, testD = next(iter(train_loader)), next(iter(test_loader))\n",
    "        trainO, testO = trainD, testD\n",
    "        # prepare data\n",
    "        if model.name in ['Attention', 'DAGMM', 'USAD', 'MSCRED', 'CAE_M', 'GDN', 'MTAD_GAT', 'MAD_GAN', 'iTransformer'] or 'TranAD' in model.name: \n",
    "            trainD, testD = convert_to_windows(trainD, model), convert_to_windows(testD, model)\n",
    "        \n",
    "        ### Testing phase\n",
    "        torch.zero_grad = True\n",
    "        model.eval()\n",
    "        lossT, _ = backprop(0, model, trainD, trainO, optimizer, scheduler, training=False)  # training loss for POT\n",
    "        loss, y_pred = backprop(0, model, testD, testO, optimizer, scheduler, training=False)\n",
    "\n",
    "        preds = []\n",
    "        for i in range(loss.shape[1]):\n",
    "            lt, l, ls = lossT[:, i], loss[:, i], labels[:, i]\n",
    "            result, pred = pot_eval(lt, l, ls, plot_path, f'dim{i}')\n",
    "            preds.append(pred)\n",
    "            df_res = pd.DataFrame.from_dict(result, orient='index').T\n",
    "        lossTfinal, lossFinal = np.mean(lossT, axis=1), np.mean(loss, axis=1)\n",
    "        labelsFinal = (np.sum(labels, axis=1) >= 1) + 0\n",
    "        preds = np.array(preds).T\n",
    "        preds = preds.astype(int)\n",
    "        df_labels = pd.DataFrame(preds)\n",
    "        labelspred = (np.sum(preds, axis=1) >= 1) + 0\n",
    "        print(loss.shape, labelsFinal.shape)\n",
    "        \n",
    "        plot_ascore(plot_path, 'ascore_local', loss, labelsFinal)\n",
    "        plot_labels(plot_path, 'labels_local', labelspred, labelsFinal)\n",
    "        plot_metrics(plot_path, 'metrics_local', labelspred, labelsFinal)\n",
    "\n",
    "        result2, pred2 = pot_eval(lossTfinal, lossFinal, labelsFinal, plot_path, f'all_dim')\n",
    "        labelspred2 = (pred2 >= 1) + 0\n",
    "        plot_ascore(plot_path, 'ascore_global', lossFinal, labelsFinal)\n",
    "        plot_labels(plot_path, 'labels_global', labelspred2, labelsFinal)\n",
    "        plot_metrics(plot_path, 'metrics_global', labelspred2, labelsFinal)\n",
    "        \n",
    "        # arr = np.where(labelspred!=labelspred2)\n",
    "        # print(len(arr[0]), len(np.where(labelspred==labelspred2)[0]))\n",
    "\n",
    "        compare_labels(plot_path, labels_loc=labelspred, labels_glob=labelspred2, labels=labelsFinal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replotting('TranAD', TranAD_n_windows, dataset, 25)\n",
    "replotting('iTransformer', iTransf_n_windows, dataset, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply POT directly to ATLAS time series features without applying any model before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from main import load_dataset\n",
    "from src.pot import calc_point2point\n",
    "from src.pot import pot_eval\n",
    "from src.plotting import plot_ascore, plot_labels, plot_metrics, compare_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: (37826, 16)\n",
      "test set shape: (36830, 16)\n",
      "torch.Size([37826, 16]) torch.Size([36830, 16]) (36830, 16)\n",
      "(37826, 16) (36830, 16) (36830, 16)\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, label = load_dataset('ATLAS_TS')\n",
    "train, test = next(iter(train_loader)), next(iter(test_loader))\n",
    "print(train.shape, test.shape, label.shape)\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "labels = np.array(label)\n",
    "print(train.shape, test.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossT = np.abs(train)\n",
    "loss = np.abs(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ATLAS_TS'\n",
    "res_path = f'results/{dataset}'\n",
    "plot_path = res_path\n",
    "os.makedirs(plot_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauraboggia/VSCode_projects/TranAD/src/spot.py:314: RuntimeWarning: divide by zero encountered in log\n",
      "  return 1 + np.log(s).mean()\n",
      "/Users/lauraboggia/VSCode_projects/TranAD/src/spot.py:317: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.mean(1 / s)\n",
      "/Users/lauraboggia/VSCode_projects/TranAD/src/spot.py:330: RuntimeWarning: divide by zero encountered in divide\n",
      "  jac_vs = (1 / t) * (-vs + np.mean(1 / s ** 2))\n",
      "/Users/lauraboggia/VSCode_projects/TranAD/src/spot.py:330: RuntimeWarning: invalid value encountered in scalar add\n",
      "  jac_vs = (1 / t) * (-vs + np.mean(1 / s ** 2))\n",
      "/Users/lauraboggia/VSCode_projects/TranAD/src/spot.py:314: RuntimeWarning: divide by zero encountered in log\n",
      "  return 1 + np.log(s).mean()\n",
      "/Users/lauraboggia/VSCode_projects/TranAD/src/spot.py:317: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.mean(1 / s)\n",
      "/Users/lauraboggia/VSCode_projects/TranAD/src/spot.py:330: RuntimeWarning: divide by zero encountered in divide\n",
      "  jac_vs = (1 / t) * (-vs + np.mean(1 / s ** 2))\n",
      "/Users/lauraboggia/VSCode_projects/TranAD/src/spot.py:330: RuntimeWarning: invalid value encountered in scalar add\n",
      "  jac_vs = (1 / t) * (-vs + np.mean(1 / s ** 2))\n"
     ]
    }
   ],
   "source": [
    "# local anomaly labels\n",
    "df_res_local = pd.DataFrame()\n",
    "preds = []\n",
    "for i in range(loss.shape[1]):\n",
    "    if dataset in ['IEEECIS']:\n",
    "        lt, l, ls = lossT[:, i], loss[:, i], labels[:]  # labels[i] for IEEECIS-TS\n",
    "    else:\n",
    "        lt, l, ls = lossT[:, i], loss[:, i], labels[:, i]  # labels[i] for IEEECIS-TS\n",
    "    result_local, pred = pot_eval(lt, l, ls, plot_path, f'dim{i}', q=1e-5)\n",
    "    preds.append(pred)\n",
    "    df_res = pd.DataFrame.from_dict(result_local, orient='index').T\n",
    "    df_res_local = pd.concat([df_res_local, df_res], ignore_index=True)\n",
    "lossTfinal, lossFinal = np.mean(lossT, axis=1), np.mean(loss, axis=1)\n",
    "true_labels = (np.sum(labels, axis=1) >= 1) + 0\n",
    "preds = np.array(preds).T\n",
    "preds = preds.astype(int)\n",
    "labelspred = (np.sum(preds, axis=1) >= 1) + 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local results\n",
      "{'f1': 0.0637431603211496, 'precision': 0.03555555476543212, 'recall': 0.3076922485207214, 'TP': 16, 'TN': 36344, 'FP': 434, 'FN': 36, 'ROC/AUC': 0.6479458873825071, 'MCC': 0.1011325632008082}\n",
      "\n",
      "local results with majority voting\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'TP': 0, 'TN': 36778, 'FP': 0, 'FN': 52, 'ROC/AUC': 0.5, 'MCC': 0.0}\n",
      "(array([ 2490,  3735,  4360,  4995,  7533,  8435,  9176, 10306, 10884,\n",
      "       11084, 11115, 11178, 11617, 13640, 13825, 15153, 15962, 16128,\n",
      "       16236, 16321, 16372, 16471, 16635, 16651, 16786, 18447, 20484,\n",
      "       21494, 22032, 22814, 23087, 24040, 24644, 25589, 25721, 26175,\n",
      "       26345, 26471, 26576, 27891, 27968, 28500, 28652, 29369, 31439,\n",
      "       32203, 32382, 32476, 32791, 34436, 36280, 36658]),) False\n",
      "\n",
      "global results\n",
      "{'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'TP': 0, 'TN': 36739, 'FP': 39, 'FN': 52, 'ROC/AUC': 0.49946979172331285, 'MCC': -0.0012242472155354763, 'threshold': 0.14219402978949508}\n"
     ]
    }
   ],
   "source": [
    "plot_ascore(plot_path, 'ascore_local', ascore=loss, labels=true_labels)\n",
    "plot_labels(plot_path, 'labels_local', y_pred=labelspred, y_true=true_labels)\n",
    "plot_metrics(plot_path, 'metrics_local', y_pred=labelspred, y_true=true_labels)\n",
    "result_local = calc_point2point(predict=labelspred, actual=true_labels)\n",
    "result_local1 = {'f1': result_local[0], 'precision': result_local[1], 'recall': result_local[2], \n",
    "                'TP': result_local[3], 'TN': result_local[4], 'FP': result_local[5], 'FN': result_local[6], \n",
    "                'ROC/AUC': result_local[7], 'MCC': result_local[8]}\n",
    "print('local results')\n",
    "print(result_local1)\n",
    "\n",
    "# do majority voting over dimensions for local results instead of inclusive OR\n",
    "majority = math.ceil(labels.shape[1] / 2)\n",
    "labelspred_maj = (np.sum(preds, axis=1) >= majority) + 0\n",
    "plot_labels(plot_path, 'labels_local_maj', y_pred=labelspred_maj, y_true=true_labels)\n",
    "plot_metrics(plot_path, 'metrics_local_maj', y_pred=labelspred_maj, y_true=true_labels)\n",
    "result_local = calc_point2point(predict=labelspred_maj, actual=true_labels)\n",
    "result_local2 = {'f1': result_local[0], 'precision': result_local[1], 'recall': result_local[2], \n",
    "                'TP': result_local[3], 'TN': result_local[4], 'FP': result_local[5], 'FN': result_local[6], \n",
    "                'ROC/AUC': result_local[7], 'MCC': result_local[8]}\n",
    "print('\\nlocal results with majority voting')\n",
    "print(result_local2)\n",
    "temp = np.where(labelspred_maj != true_labels)\n",
    "print(temp, np.all(labelspred_maj == true_labels))\n",
    "\n",
    "# global anomaly labels\n",
    "result_global, pred2 = pot_eval(lossTfinal, lossFinal, true_labels, plot_path, f'all_dim', q=1e-5)\n",
    "labelspred_glob = (pred2 >= 1) + 0\n",
    "plot_ascore(plot_path, 'ascore_global', ascore=lossFinal, labels=true_labels)\n",
    "plot_labels(plot_path, 'labels_global', y_pred=labelspred_glob, y_true=true_labels)\n",
    "plot_metrics(plot_path, 'metrics_global', y_pred=labelspred_glob, y_true=true_labels)\n",
    "metrics_global = calc_point2point(predict=labelspred_glob, actual=true_labels)\n",
    "# result_global.update(hit_att(loss, labels))\n",
    "# result_global.update(ndcg(loss, labels))\n",
    "print('\\nglobal results') \n",
    "print(result_global)\n",
    "\n",
    "# compare local & global anomaly labels\n",
    "compare_labels(plot_path, pred_labels=[labelspred, labelspred_maj], true_labels=true_labels, \n",
    "            plot_labels=['Local anomaly\\n(inclusive OR)', 'Local anomaly\\n(majority voting)'], name='_loc_vs_maj')\n",
    "compare_labels(plot_path, pred_labels=[labelspred, labelspred_maj, labelspred_glob], true_labels=true_labels, \n",
    "            plot_labels=['Local anomaly\\n(inclusive OR)', 'Local anomaly\\n(majority voting)', 'Global anomaly'], name='_all')\n",
    "\n",
    "# saving results\n",
    "df_res_global = pd.DataFrame.from_dict(result_global, orient='index').T\n",
    "df_res_global.index = ['global']\n",
    "result_local1 = pd.DataFrame.from_dict(result_local1, orient='index').T\n",
    "result_local2 = pd.DataFrame.from_dict(result_local2, orient='index').T\n",
    "result_local1.index = ['local_all']\n",
    "result_local2.index = ['local_all_maj']\n",
    "df_res_local = pd.concat([df_res_local, result_local1, result_local2])\n",
    "df_res = pd.concat([df_res_local, df_res_global]) \n",
    "df_labels = pd.DataFrame( {'local': labelspred, 'local_maj': labelspred_maj, 'global': labelspred_glob} )\n",
    "\n",
    "df_res.to_csv(f'{res_path}/res.csv')\t\n",
    "df_labels.to_csv(f'{res_path}/pred_labels.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
