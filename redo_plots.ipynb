{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauraboggia/Library/CloudStorage/Box-Box/Laura_PhD/VSCode_projects/iTransformerAD/.conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'convert_to_windows_new' from 'src.data_loader' (/Users/lauraboggia/Library/CloudStorage/Box-Box/Laura_PhD/VSCode_projects/iTransformerAD/src/data_loader.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_windows_new\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'convert_to_windows_new' from 'src.data_loader' (/Users/lauraboggia/Library/CloudStorage/Box-Box/Laura_PhD/VSCode_projects/iTransformerAD/src/data_loader.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import mplhep as hep\n",
    "from src.models import TranAD, iTransformer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from src.data_loader import convert_to_windows_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['axes.prop_cycle'] = cycler('color', ['#17becf','#8c564b', '#e377c2', '#7f7f7f','#bcbd22', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])\n",
    "plt.style.use([hep.style.ROOT, hep.style.firamath])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### redo older plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iTransf_n_windows = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 500, 1000, 2000]\n",
    "TranAD_n_windows = [10, 20, 30, 40, 50, 60, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25\n",
    "dataset = 'SMAP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_dataset(dataset):\n",
    "# \tloader = []\n",
    "# \tfor file in ['train', 'test', 'labels']:\n",
    "# \t\tif dataset == 'SMD': file = 'machine-1-1_' + file\n",
    "# \t\tif dataset == 'SMAP': file = 'P-1_' + file\n",
    "# \t\tif dataset == 'MSL': file = 'C-1_' + file\n",
    "# \t\tif dataset == 'UCR': file = '136_' + file\n",
    "# \t\tif dataset == 'NAB': file = 'ec2_request_latency_system_failure_' + file\n",
    "# \t\tloader.append(np.load(os.path.join(f'processed/{dataset}', f'{file}.npy')))\n",
    "\t\n",
    "# \ttrain_loader = DataLoader(loader[0], batch_size=loader[0].shape[0])\n",
    "# \ttest_loader = DataLoader(loader[1], batch_size=loader[1].shape[0])\n",
    "# \tlabels = loader[2]\n",
    "# \tprint('training set shape:', train_loader.dataset.shape)\n",
    "# \tprint('test set shape:', test_loader.dataset.shape)\n",
    "# \treturn train_loader, test_loader, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plotting import plot_ascore, plot_labels, plot_metrics, compare_labels\n",
    "from main import backprop\n",
    "from src.pot import pot_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replotting(model_name, n_windows, dataset='SMAP', N=25):\n",
    "    for i, elem in enumerate(n_windows):\n",
    "        # path = f'studies/{model_name}_{dataset}_2/n_window{elem}/results'\n",
    "        model_path = f'studies/{model_name}_{dataset}_2/n_window{elem}/checkpoints/model.ckpt'\n",
    "        plot_path = f'studies/{model_name}_{dataset}_2/n_window{elem}/plots'\n",
    "\n",
    "        # initialise model etc\n",
    "        checkpoint = torch.load(model_path)\n",
    "        if model_name == 'TranAD':\n",
    "            model = TranAD(N, elem).double()\n",
    "        elif model_name == 'iTransformer':\n",
    "            model = iTransformer(N, elem).double()\n",
    "        else:\n",
    "            print('pbm with model loading')\n",
    "            break\n",
    "        optimizer = torch.optim.AdamW(model.parameters() , lr=model.lr, weight_decay=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 5, 0.9)\n",
    "        # load model etc\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        # epoch = checkpoint['epoch']\n",
    "        # accuracy_list = checkpoint['accuracy_list']\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f'total params: {total_params}, trainable params: {trainable_params}')\n",
    "\n",
    "        train_loader, test_loader, labels = load_dataset(dataset)\n",
    "        trainD, testD = next(iter(train_loader)), next(iter(test_loader))\n",
    "        trainO, testO = trainD, testD\n",
    "        # prepare data\n",
    "        if model.name in ['Attention', 'DAGMM', 'USAD', 'MSCRED', 'CAE_M', 'GDN', 'MTAD_GAT', 'MAD_GAN', 'iTransformer'] or 'TranAD' in model.name: \n",
    "            trainD, testD = convert_to_windows(trainD, model), convert_to_windows(testD, model)\n",
    "        \n",
    "        ### Testing phase\n",
    "        torch.zero_grad = True\n",
    "        model.eval()\n",
    "        lossT, _ = backprop(0, model, trainD, trainO, optimizer, scheduler, training=False)  # training loss for POT\n",
    "        loss, y_pred = backprop(0, model, testD, testO, optimizer, scheduler, training=False)\n",
    "\n",
    "        preds = []\n",
    "        for i in range(loss.shape[1]):\n",
    "            lt, l, ls = lossT[:, i], loss[:, i], labels[:, i]\n",
    "            result, pred = pot_eval(lt, l, ls, plot_path, f'dim{i}')\n",
    "            preds.append(pred)\n",
    "            df_res = pd.DataFrame.from_dict(result, orient='index').T\n",
    "        lossTfinal, lossFinal = np.mean(lossT, axis=1), np.mean(loss, axis=1)\n",
    "        labelsFinal = (np.sum(labels, axis=1) >= 1) + 0\n",
    "        preds = np.array(preds).T\n",
    "        preds = preds.astype(int)\n",
    "        df_labels = pd.DataFrame(preds)\n",
    "        labelspred = (np.sum(preds, axis=1) >= 1) + 0\n",
    "        print(loss.shape, labelsFinal.shape)\n",
    "        \n",
    "        plot_ascore(plot_path, 'ascore_local', loss, labelsFinal)\n",
    "        plot_labels(plot_path, 'labels_local', labelspred, labelsFinal)\n",
    "        plot_metrics(plot_path, 'metrics_local', labelspred, labelsFinal)\n",
    "\n",
    "        result2, pred2 = pot_eval(lossTfinal, lossFinal, labelsFinal, plot_path, f'all_dim')\n",
    "        labelspred2 = (pred2 >= 1) + 0\n",
    "        plot_ascore(plot_path, 'ascore_global', lossFinal, labelsFinal)\n",
    "        plot_labels(plot_path, 'labels_global', labelspred2, labelsFinal)\n",
    "        plot_metrics(plot_path, 'metrics_global', labelspred2, labelsFinal)\n",
    "        \n",
    "        # arr = np.where(labelspred!=labelspred2)\n",
    "        # print(len(arr[0]), len(np.where(labelspred==labelspred2)[0]))\n",
    "\n",
    "        compare_labels(plot_path, labels_loc=labelspred, labels_glob=labelspred2, labels=labelsFinal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replotting('TranAD', TranAD_n_windows, dataset, 25)\n",
    "replotting('iTransformer', iTransf_n_windows, dataset, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply POT directly to ATLAS time series features without applying any model before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from main import load_dataset\n",
    "from src.pot import calc_point2point\n",
    "from src.pot import pot_eval\n",
    "from src.plotting import plot_ascore, plot_labels, plot_metrics, compare_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'GECCO'\n",
    "feats = -1\n",
    "res_path = f'None/None_{dataset}/feats{feats}'\n",
    "plot_path = res_path\n",
    "os.makedirs(plot_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader, label, _ = load_dataset(dataset, feats=feats, less=False)\n",
    "train, test = next(iter(train_loader)), next(iter(test_loader))\n",
    "print(train.shape, test.shape, label.shape)\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "labels = np.array(label)\n",
    "print(train.shape, test.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossT = np.abs(train)\n",
    "loss = np.abs(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local anomaly labels\n",
    "df_res_local = pd.DataFrame()\n",
    "preds = []\n",
    "for i in range(loss.shape[1]):\n",
    "    lt, l, ls = lossT[:, i], loss[:, i], labels[:, i]  \n",
    "    result_local, pred = pot_eval(lt, l, ls, plot_path, f'dim{i}', q=1e-5)\n",
    "    preds.append(pred)\n",
    "    df_res = pd.DataFrame.from_dict(result_local, orient='index').T\n",
    "    df_res_local = pd.concat([df_res_local, df_res], ignore_index=True)\n",
    "lossTfinal, lossFinal = np.mean(lossT, axis=1), np.mean(loss, axis=1)\n",
    "true_labels = (np.sum(labels, axis=1) >= 1) + 0\n",
    "preds = np.array(preds).T\n",
    "preds = preds.astype(int)\n",
    "labelspred = (np.sum(preds, axis=1) >= 1) + 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ascore(plot_path, 'ascore_local', ascore=loss, labels=true_labels)\n",
    "plot_labels(plot_path, 'labels_local', y_pred=labelspred, y_true=true_labels)\n",
    "result_local = calc_point2point(predict=labelspred, actual=true_labels)\n",
    "result_local1 = {'f1': result_local[0], 'precision': result_local[1], 'recall': result_local[2], \n",
    "                'TP': result_local[3], 'TN': result_local[4], 'FP': result_local[5], 'FN': result_local[6], \n",
    "                'ROC/AUC': result_local[7], 'MCC': result_local[8]}\n",
    "print('local results')\n",
    "print(result_local1)\n",
    "\n",
    "# do majority voting over dimensions for local results instead of inclusive OR\n",
    "majority = math.ceil(labels.shape[1] / 2)\n",
    "labelspred_maj = (np.sum(preds, axis=1) >= majority) + 0\n",
    "plot_labels(plot_path, 'labels_local_maj', y_pred=labelspred_maj, y_true=true_labels)\n",
    "result_local = calc_point2point(predict=labelspred_maj, actual=true_labels)\n",
    "result_local2 = {'f1': result_local[0], 'precision': result_local[1], 'recall': result_local[2], \n",
    "                'TP': result_local[3], 'TN': result_local[4], 'FP': result_local[5], 'FN': result_local[6], \n",
    "                'ROC/AUC': result_local[7], 'MCC': result_local[8]}\n",
    "print('\\nlocal results with majority voting')\n",
    "print(result_local2)\n",
    "temp = np.where(labelspred_maj != true_labels)\n",
    "print(temp, np.all(labelspred_maj == true_labels))\n",
    "\n",
    "# global anomaly labels\n",
    "result_global, pred2 = pot_eval(lossTfinal, lossFinal, true_labels, plot_path, f'all_dim', q=1e-5)\n",
    "labelspred_glob = (pred2 >= 1) + 0\n",
    "plot_ascore(plot_path, 'ascore_global', ascore=lossFinal, labels=true_labels)\n",
    "plot_labels(plot_path, 'labels_global', y_pred=labelspred_glob, y_true=true_labels)\n",
    "metrics_global = calc_point2point(predict=labelspred_glob, actual=true_labels)\n",
    "print('\\nglobal results') \n",
    "print(result_global)\n",
    "\n",
    "plot_metrics(plot_path, ['local (incl. OR)', 'local (maj. voting)', 'global'], \n",
    "\t\t\t  y_pred=[labelspred, labelspred_maj, labelspred_glob], y_true=true_labels)\n",
    "\n",
    "# compare local & global anomaly labels\n",
    "compare_labels(plot_path, pred_labels=[labelspred, labelspred_maj], true_labels=true_labels, \n",
    "            plot_labels=['Local anomaly\\n(inclusive OR)', 'Local anomaly\\n(majority voting)'], name='_loc_vs_maj')\n",
    "compare_labels(plot_path, pred_labels=[labelspred, labelspred_maj, labelspred_glob], true_labels=true_labels, \n",
    "            plot_labels=['Local anomaly\\n(inclusive OR)', 'Local anomaly\\n(majority voting)', 'Global anomaly'], name='_all')\n",
    "\n",
    "# saving results\n",
    "df_res_global = pd.DataFrame.from_dict(result_global, orient='index').T\n",
    "df_res_global.index = ['global']\n",
    "result_local1 = pd.DataFrame.from_dict(result_local1, orient='index').T\n",
    "result_local2 = pd.DataFrame.from_dict(result_local2, orient='index').T\n",
    "result_local1.index = ['local_all']\n",
    "result_local2.index = ['local_all_maj']\n",
    "df_res_local = pd.concat([df_res_local, result_local1, result_local2])\n",
    "df_res = pd.concat([df_res_local, df_res_global]) \n",
    "df_labels = pd.DataFrame( {'local': labelspred, 'local_maj': labelspred_maj, 'global': labelspred_glob} )\n",
    "\n",
    "df_res.to_csv(f'{res_path}/res.csv')\t\n",
    "df_labels.to_csv(f'{res_path}/pred_labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test Isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from src.data_loader_old import load_dataset\n",
    "from src.pot import calc_point2point\n",
    "from src.pot import pot_eval\n",
    "from src.plotting import plot_ascore, plot_labels, plot_metrics, compare_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'creditcard'\n",
    "feats = -1\n",
    "contamination = 0.01\n",
    "res_path = f'IF/IF_{dataset}/feats{feats}'\n",
    "plot_path = f'{res_path}/plots'\n",
    "os.makedirs(plot_path, exist_ok=True)\n",
    "res_path = f'{res_path}/results'\n",
    "os.makedirs(res_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: (199364, 29)\n",
      "test set shape: (85443, 29)\n",
      "labels shape: (85443, 29)\n",
      "ts_lengths 0: 199364\n",
      "ts_lengths 1: 85443\n",
      "torch.Size([199364, 29]) torch.Size([85443, 29]) (85443, 29)\n",
      "(199364, 29) (85443, 29) (85443, 29)\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, labels, _, _ = load_dataset(dataset, feats=feats)\n",
    "train, test = next(iter(train_loader)), next(iter(test_loader))\n",
    "print(train.shape, test.shape, labels.shape)\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "labels = np.array(labels)\n",
    "print(train.shape, test.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036656016291562794 3132\n"
     ]
    }
   ],
   "source": [
    "# print(len(labels[:,0][labels[:,0]==1])/len(labels[:,0]))\n",
    "print(len(labels[labels==1])/len(labels), len(labels[labels==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolation forest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "clf = IsolationForest(contamination=contamination, random_state=0).fit(train)\n",
    "lossTfinal = clf.decision_function(train)\n",
    "lossFinal = clf.decision_function(test)\n",
    "labelspredIF = clf.predict(test)\n",
    "labelspredIF = (labelspredIF == -1) + 0\n",
    "print(len(labelspredIF[labelspredIF == 1]), len(labelspredIF[labelspredIF == 0]))\n",
    "print(labelspredIF.shape)\n",
    "print(lossTfinal.shape, lossFinal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = (np.sum(labels, axis=1) >= 1) + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_labels(plot_path, 'labels_local', y_pred=labelspredIF, y_true=true_labels)\n",
    "metrics_IF = calc_point2point(predict=labelspredIF, actual=true_labels)\n",
    "result_IF = {'f1': metrics_IF[0], 'precision': metrics_IF[1], 'recall': metrics_IF[2],\n",
    "            'TP': metrics_IF[3], 'TN': metrics_IF[4], 'FP': metrics_IF[5], 'FN': metrics_IF[6],\n",
    "            'ROC/AUC': metrics_IF[7], 'MCC': metrics_IF[8]}\n",
    "print('IF results')\n",
    "print(result_IF)\n",
    "df_res_IF = pd.DataFrame.from_dict(result_IF, orient='index').T\n",
    "\n",
    "\n",
    "# global anomaly labels\n",
    "result_global, pred2 = pot_eval(lossTfinal, lossFinal, true_labels, plot_path, f'all_dim', q=1e-5)\n",
    "labelspred_glob = (pred2 >= 1) + 0\n",
    "plot_ascore(plot_path, 'ascore_global', ascore=lossFinal, labels=true_labels)\n",
    "plot_labels(plot_path, 'labels_global', y_pred=labelspred_glob, y_true=true_labels)\n",
    "metrics_global = calc_point2point(predict=labelspred_glob, actual=true_labels)\n",
    "print('\\nglobal results') \n",
    "print(result_global)\n",
    "\n",
    "plot_metrics(plot_path, ['IF', 'global'], \n",
    "\t\t\t  y_pred=[labelspredIF, labelspred_glob], y_true=true_labels)\n",
    "\n",
    "# compare local & global anomaly labels\n",
    "compare_labels(plot_path, pred_labels=[labelspredIF, labelspred_glob], true_labels=true_labels, \n",
    "            plot_labels=['Anomaly from IF', 'Global anomaly'], name='_all')\n",
    "\n",
    "# saving results\n",
    "df_res_global = pd.DataFrame.from_dict(result_global, orient='index').T\n",
    "df_res_global.index = ['global']\n",
    "df_res = pd.concat([df_res_IF, df_res_global]) \n",
    "df_labels = pd.DataFrame( {'IF': labelspredIF, 'global': labelspred_glob} )\n",
    "\n",
    "df_res.to_csv(f'{res_path}/res.csv')\t\n",
    "df_labels.to_csv(f'{res_path}/pred_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
